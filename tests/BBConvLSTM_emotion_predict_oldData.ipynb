{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copyright Netherlands eScience Center and Centrum Wiskunde & Informatica <br>\n",
    "** Function     : Emotion recognition and forecast with ConvLSTM** <br>\n",
    "** Author       : Yang Liu & Tianyi Zhang** <br>\n",
    "** First Built  : 2020.05.17 ** <br>\n",
    "** Last Update  : 2020.05.22 ** <br>\n",
    "** Library      : Pytorth, Numpy, os, DLACs, matplotlib **<br>\n",
    "Description     : This notebook serves to test the prediction skill of deep neural networks in emotion recognition and forecast. The convolutional Long Short Time Memory neural network is used to deal with this spatial-temporal sequence problem. We use Pytorch as the deep learning framework. <br>\n",
    "<br>\n",
    "** Many to one prediction.** <br>\n",
    "\n",
    "Return Values   : Time series and figures <br>\n",
    "\n",
    "**This project is a joint venture between NLeSC and CWI** <br>\n",
    "\n",
    "The method comes from the study by Shi et. al. (2015) Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import numbers\n",
    "\n",
    "# for data loading\n",
    "import os\n",
    "# for pre-processing and machine learning\n",
    "import numpy as np\n",
    "import csv\n",
    "#import sklearn\n",
    "#import scipy\n",
    "import torch\n",
    "import torch.nn.functional\n",
    "\n",
    "sys.path.append(\"C:\\\\Users\\\\nosta\\\\ConvLSTM_emotion\\\\Scripts\\\\DLACs\")\n",
    "#sys.path.append(\"../\")\n",
    "import nemo\n",
    "import nemo.ConvLSTM\n",
    "import nemo.BBConvLSTM\n",
    "import nemo.function\n",
    "import nemo.metric\n",
    "\n",
    "# for visualization\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The testing device is Dell Inspirion 5680 with Intel Core i7-8700 x64 CPU and Nvidia GTX 1060 6GB GPU.<br>\n",
    "Here is a benchmark about cpu v.s. gtx 1060 <br>\n",
    "https://www.analyticsindiamag.com/deep-learning-tensorflow-benchmark-intel-i5-4210u-vs-geforce-nvidia-1060-6gb/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################# \n",
    "#########                           datapath                             ########\n",
    "#################################################################################\n",
    "# please specify data path\n",
    "datapath = 'C:\\\\Users\\\\nosta\\\\ConvLSTM_emotion\\\\Data_CASE'\n",
    "output_path = 'C:\\\\Users\\\\nosta\\\\ConvLSTM_emotion\\\\results'\n",
    "model_path = 'C:\\\\Users\\\\nosta\\\\ConvLSTM_emotion\\\\models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    print ('*********************** extract variables *************************')\n",
    "    data = np.load(os.path.join(datapath, \"data_10s.npz\"))\n",
    "    #data = np.load(os.path.join(datapath, \"data_2s.npz\"))\n",
    "    #data = np.load(os.path.join(datapath, \"data_0.5s.npz\"))\n",
    "    #################################################################################\n",
    "    #########                        data gallery                           #########\n",
    "    #################################################################################\n",
    "    sample = data[\"Samples\"][:] # (batch_size, sample_size, channels)\n",
    "    label_c = data[\"Labels_c\"][:] # (batch_size, sample_size, 2)\n",
    "    label = data[\"Labels\"][:] # (batch_size, 2)\n",
    "    subject = data[\"Subject_id\"][:] # (batch_size, 2)\n",
    "    video_label = data[\"Video_labels\"][:] # (batch_size,1)\n",
    "    \n",
    "    # leave-one-out training and testing\n",
    "    num_s = 2\n",
    "    sample_train = sample[np.where(subject!=num_s)[0],:,0:5]\n",
    "    sample_test = sample[np.where(subject==num_s)[0],:,0:5]\n",
    "    \n",
    "    label_c_train = label_c[np.where(subject!=num_s)[0],:,:] / 10 # normalize\n",
    "    label_c_test = label_c[np.where(subject==num_s)[0],:,:] / 10 # normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #################################################################################\n",
    "    #########                      pre-processing                           #########\n",
    "    #################################################################################\n",
    "    # choose the target dimension for reshaping of the signals\n",
    "    batch_train_size, sample_size, channels = sample_train.shape\n",
    "    batch_test_size, _, _ = sample_test.shape\n",
    "    _, _, label_channels = label_c_train.shape\n",
    "    x_dim = 5\n",
    "    y_dim = 5\n",
    "    series_len = sample_size // (y_dim * x_dim)\n",
    "    # reshape the input and labels\n",
    "    sample_train_xy = np.reshape(sample_train,[batch_train_size, series_len, y_dim, x_dim, channels])\n",
    "    sample_test_xy = np.reshape(sample_test,[batch_test_size, series_len, y_dim, x_dim, channels])\n",
    "    label_c_train_xy = np.reshape(label_c_train,[batch_train_size, series_len, y_dim, x_dim, label_channels])\n",
    "    label_c_test_xy = np.reshape(label_c_test,[batch_test_size, series_len, y_dim, x_dim, label_channels])\n",
    "    #################################################################################\n",
    "    #########                       normalization                           #########\n",
    "    #################################################################################\n",
    "    print('================  extract individual variables  =================')\n",
    "    sample_1 = sample_train_xy[:,:,:,:,0]\n",
    "    sample_2 = sample_train_xy[:,:,:,:,1]\n",
    "    sample_3 = sample_train_xy[:,:,:,:,2]\n",
    "    sample_4 = sample_train_xy[:,:,:,:,3]\n",
    "    sample_5 = sample_train_xy[:,:,:,:,4]\n",
    "    \n",
    "    sample_1_test = sample_test_xy[:,:,:,:,0]\n",
    "    sample_2_test = sample_test_xy[:,:,:,:,1]\n",
    "    sample_3_test = sample_test_xy[:,:,:,:,2]\n",
    "    sample_4_test = sample_test_xy[:,:,:,:,3]\n",
    "    sample_5_test = sample_test_xy[:,:,:,:,4]   \n",
    "    \n",
    "    label_c_valance = label_c_train_xy[:,:,:,:,0]\n",
    "    label_c_arousal = label_c_train_xy[:,:,:,:,1]\n",
    "    \n",
    "    label_c_test_valance = label_c_test_xy[:,:,:,:,0]\n",
    "    label_c_test_arousal = label_c_test_xy[:,:,:,:,1]\n",
    "    \n",
    "    # using indicator for training\n",
    "    # video_label_3D = np.repeat(video_label[:,np.newaxis,:],series_len,1)\n",
    "    # video_label_4D = np.repeat(video_label_3D[:,:,np.newaxis,:],y_dim,2)\n",
    "    # video_label_xy = np.repeat(video_label_4D[:,:,:,np.newaxis,:],x_dim,3)\n",
    "    # video_label_xy.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    # first check of data shape\n",
    "    print(sample.shape)\n",
    "    print(label_c.shape)\n",
    "    print(label.shape)\n",
    "    print(subject.shape)\n",
    "    print(video_label.shape)\n",
    "    # check of reshape\n",
    "    print(label_c_train_xy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procedure for LSTM <br>\n",
    "** We use Pytorth to implement LSTM neural network with time series of climate data. ** <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    print ('*******************  create basic dimensions for tensor and network  *********************')\n",
    "    # specifications of neural network\n",
    "    input_channels = 5\n",
    "    hidden_channels = [4, 3, 2] # number of channels & hidden layers, the channels of last layer is the channels of output, too\n",
    "    #hidden_channels = [3, 3, 3, 3, 2]\n",
    "    #hidden_channels = [2]\n",
    "    kernel_size = 3\n",
    "    # here we input a sequence and predict the next step only\n",
    "    learning_rate = 0.01\n",
    "    num_epochs = 200\n",
    "    # probability of dropout\n",
    "    p = 0.8 # 0.5 for Bernoulli (binary) distribution\n",
    "    print (torch.__version__)\n",
    "    # check if CUDA is available\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    print(\"Is CUDA available? {}\".format(use_cuda))\n",
    "    # CUDA settings torch.__version__ must > 0.4\n",
    "    # !!! This is important for the model!!! The first option is gpu\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print ('*******************  cross validation and testing data  *********************')\n",
    "    # mini-batch\n",
    "    mini_batch_size = 64\n",
    "    # iterations\n",
    "    iterations = batch_train_size // mini_batch_size\n",
    "    if batch_train_size % mini_batch_size != 0:\n",
    "        extra_loop = \"True\"\n",
    "        iterations += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    %%time\n",
    "    print ('*******************  load exsited LSTM model  *********************')\n",
    "    # load model parameters\n",
    "    model = dlacs.BBConvLSTM.BBConvLSTM(input_channels, hidden_channels, kernel_size).to(device)\n",
    "    model.load_state_dict(torch.load(os.path.join(model_path, 'BBconvlstm_emotion_hl_3_kernel_3_lr_0.01_epoch_20_mini_64.pkl'),\n",
    "                                     map_location=device))\n",
    "    #model = torch.load(os.path.join(output_path, 'Barents','convlstm_emotion_hl_1_kernel_3_lr_0.01_epoch_500.pkl'))\n",
    "    print(model)\n",
    "    # check the sequence length (dimension in need for post-processing)\n",
    "    _, sequence_len, height, width = sample_1_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print (name)\n",
    "            print (param.data)\n",
    "            print (param.size())\n",
    "            print (\"=========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    print('##############################################################')\n",
    "    print('#############  preview model parameters matrix  ###############')\n",
    "    print('##############################################################')\n",
    "    print('Number of parameter matrices: ', len(list(model.parameters())))\n",
    "    for i in range(len(list(model.parameters()))):\n",
    "        print(list(model.parameters())[i].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    print ('*******************  evaluation matrix  *********************')\n",
    "    # The prediction will be evaluated through RMSE against climatology\n",
    "    \n",
    "    # error score for temporal-spatial fields, without keeping spatial pattern\n",
    "    def RMSE(x,y):\n",
    "        \"\"\"\n",
    "        Calculate the RMSE. x is input series and y is reference series.\n",
    "        It calculates RMSE over the domain, not over time. The spatial structure\n",
    "        will not be kept.\n",
    "        Parameter\n",
    "        ----------------------\n",
    "        x: input time series with the shape [time, lat, lon]\n",
    "        \"\"\"\n",
    "        x_series = x.reshape(x.shape[0],-1)\n",
    "        y_series = y.reshape(y.shape[0],-1)\n",
    "        rmse = np.sqrt(np.mean((x_series - y_series)**2,1))\n",
    "        rmse_std = np.std(np.sqrt((x_series - y_series)**2,1))\n",
    "    \n",
    "        return rmse, rmse_std\n",
    "    \n",
    "    # error score for temporal-spatial fields, keeping spatial pattern\n",
    "    def MAE(x,y):\n",
    "        \"\"\"\n",
    "        Calculate the MAE. x is input series and y is reference series.\n",
    "        It calculate MAE over time and keeps the spatial structure.\n",
    "        \"\"\"\n",
    "        mae = np.mean(np.abs(x-y),0)\n",
    "        \n",
    "        return mae\n",
    "    \n",
    "    def MSE(x, y):\n",
    "        \"\"\"\n",
    "        Calculate the MSE. x is input series and y is reference series.\n",
    "        \"\"\"\n",
    "        mse = np.mean((x-y)**2)\n",
    "        \n",
    "        return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    %%time\n",
    "    #################################################################################\n",
    "    ########                           prediction                            ########\n",
    "    #################################################################################\n",
    "    print('##############################################################')\n",
    "    print('###################  start prediction loop ###################')\n",
    "    print('##############################################################')\n",
    "    # forecast array\n",
    "    pred_valance = np.zeros((batch_test_size, series_len, y_dim, x_dim),dtype=float)\n",
    "    pred_arousal = np.zeros((batch_test_size, series_len, y_dim, x_dim),dtype=float)\n",
    "    # calculate loss for each sample\n",
    "    hist_valance = np.zeros(batch_test_size)\n",
    "    hist_arousal = np.zeros(batch_test_size)\n",
    "    for n in range(batch_test_size):\n",
    "        # Clear stored gradient\n",
    "        model.zero_grad()\n",
    "        for timestep in range(sequence_len):\n",
    "            x_input = np.stack((sample_1_test[n,timestep,:,:],\n",
    "                                sample_2_test[n,timestep,:,:],\n",
    "                                sample_3_test[n,timestep,:,:],\n",
    "                                sample_4_test[n,timestep,:,:],\n",
    "                                sample_5_test[n,timestep,:,:]))\n",
    "            x_var_pred = torch.autograd.Variable(torch.Tensor(x_input).view(-1,input_channels,height,width),\n",
    "                                                 requires_grad=False).to(device)\n",
    "            # make prediction\n",
    "            last_pred, _ = model(x_var_pred, timestep)\n",
    "            # GPU data should be transferred to CPU\n",
    "            pred_valance[n,timestep,:,:] = last_pred[0,0,:,:].cpu().data.numpy()\n",
    "            pred_arousal[n,timestep,:,:] = last_pred[0,1,:,:].cpu().data.numpy()\n",
    "        # compute the error for each sample\n",
    "        hist_valance[n] = MSE(label_c_test_valance[n,:,:,:], pred_valance[n,:,:,:])\n",
    "        hist_arousal[n] = MSE(label_c_test_arousal[n,:,:,:], pred_arousal[n,:,:,:]) \n",
    "    \n",
    "    # save prediction as npz file\n",
    "    np.savez_compressed(os.path.join(output_path,'BBConvLSTM_emotion_pred.npz'),\n",
    "                        valance=pred_valance, arousal=pred_arousal)\n",
    "    # plot the error\n",
    "    print (\"*******************  Loss with time  **********************\")\n",
    "    fig00 = plt.figure()\n",
    "    plt.plot(hist_valance, 'r', label=\"Training loss - valance\")\n",
    "    plt.plot(hist_arousal, 'b', label=\"Training loss - arousal\")\n",
    "    plt.xlabel('Sample')\n",
    "    plt.ylabel('MSE Error')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    fig00.savefig(os.path.join(output_path,'BBConvLSTM_pred_mse_error.png'),dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #####################################################################################\n",
    "    ########         visualization of prediction and implement metrics           ########\n",
    "    #####################################################################################\n",
    "    # compute mse\n",
    "    mse_valance = MSE(label_c_test_valance, pred_valance)\n",
    "    print(mse_valance)\n",
    "    mse_arousal = MSE(label_c_test_arousal, pred_arousal)\n",
    "    print(mse_arousal)\n",
    "    # save output as csv file\n",
    "    with open(os.path.join(output_path, \"MSE_BBConvLSTM_emotion.csv\"), \"wt+\") as fp:\n",
    "        writer = csv.writer(fp, delimiter=\",\")\n",
    "        writer.writerow([\"emotion prediction\"])  # write header\n",
    "        writer.writerow([\"label valance\"])\n",
    "        writer.writerow([mse_valance])\n",
    "        writer.writerow([\"label arousal\"])\n",
    "        writer.writerow([mse_arousal])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
