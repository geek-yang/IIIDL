{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copyright Netherlands eScience Center and Centrum Wiskunde & Informatica <br>\n",
    "** Function     : Emotion recognition and forecast with ** <br>\n",
    "** Author       : Yang Liu & Tianyi Zhang** <br>\n",
    "** First Built  : 2020.05.17 ** <br>\n",
    "** Last Update  : 2020.05.22 ** <br>\n",
    "** Library      : Pytorth, Numpy, os, DLACs, matplotlib **<br>\n",
    "Description     : This notebook serves to test the prediction skill of deep neural networks in emotion recognition and forecast. The convolutional Long Short Time Memory neural network is used to deal with this spatial-temporal sequence problem. We use Pytorch as the deep learning framework. <br>\n",
    "<br>\n",
    "** Many to one prediction.** <br>\n",
    "\n",
    "Return Values   : Time series and figures <br>\n",
    "\n",
    "**This project is a joint venture between NLeSC and CWI** <br>\n",
    "\n",
    "The method comes from the study by Shi et. al. (2015) Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import numbers\n",
    "\n",
    "# for data loading\n",
    "import os\n",
    "# for pre-processing and machine learning\n",
    "import numpy as np\n",
    "#import sklearn\n",
    "#import scipy\n",
    "import torch\n",
    "import torch.nn.functional\n",
    "\n",
    "sys.path.append(\"C:\\\\Users\\\\nosta\\\\ConvLSTM_emotion\\\\Scripts\\\\DLACs\")\n",
    "#sys.path.append(\"../\")\n",
    "import dlacs\n",
    "import dlacs.ConvLSTM\n",
    "import dlacs.preprocess\n",
    "import dlacs.function\n",
    "import dlacs.saveNetCDF\n",
    "import dlacs.metric\n",
    "\n",
    "# for visualization\n",
    "import dlacs.visual\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The testing device is Dell Inspirion 5680 with Intel Core i7-8700 x64 CPU and Nvidia GTX 1060 6GB GPU.<br>\n",
    "Here is a benchmark about cpu v.s. gtx 1060 <br>\n",
    "https://www.analyticsindiamag.com/deep-learning-tensorflow-benchmark-intel-i5-4210u-vs-geforce-nvidia-1060-6gb/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################# \n",
    "#########                           datapath                             ########\n",
    "#################################################################################\n",
    "# please specify data path\n",
    "datapath = 'C:\\\\Users\\\\nosta\\\\ConvLSTM_emotion\\\\Data_CASE'\n",
    "output_path = 'C:\\\\Users\\\\nosta\\\\ConvLSTM_emotion\\\\results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************** extract variables *************************\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    print ('*********************** extract variables *************************')\n",
    "    data = np.load(os.path.join(datapath, \"data_10s.npz\"))\n",
    "    #data = np.load(os.path.join(datapath, \"data_2s.npz\"))\n",
    "    #data = np.load(os.path.join(datapath, \"data_0.5s.npz\"))\n",
    "    #################################################################################\n",
    "    #########                        data gallery                           #########\n",
    "    #################################################################################\n",
    "    sample = data[\"Samples\"][:] # (batch_size, sample_size, channels)\n",
    "    label_c = data[\"Labels_c\"][:] # (batch_size, sample_size, 2)\n",
    "    label = data[\"Labels\"][:] # (batch_size, 2)\n",
    "    subject = data[\"Subject_id\"][:] # (batch_size, 2)\n",
    "    video_label = data[\"Video_labels\"][:] # (batch_size,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================  extract individual variables  =================\n",
      "=========================   normalize data   ===========================\n",
      "================  save the normalizing factor  =================\n"
     ]
    }
   ],
   "source": [
    "    #################################################################################\n",
    "    #########                      pre-processing                           #########\n",
    "    #################################################################################\n",
    "    # choose the target dimension for reshaping of the signals\n",
    "    batch_size, sample_size, channels = sample.shape\n",
    "    _, _, label_channels = label_c.shape\n",
    "    x_dim = 5\n",
    "    y_dim = 5\n",
    "    series_len = sample_size // (y_dim * x_dim)\n",
    "    # reshape the input and labels\n",
    "    #sample_xy = np.reshape(sample,[batch_size, series_len, y_dim, x_dim, channels], order='F')\n",
    "    sample_xy = np.reshape(sample,[batch_size, series_len, y_dim, x_dim, channels])\n",
    "    label_c_xy = np.reshape(label_c,[batch_size, series_len, y_dim, x_dim, label_channels])\n",
    "    #################################################################################\n",
    "    #########                       normalization                           #########\n",
    "    #################################################################################\n",
    "    print('================  extract individual variables  =================')\n",
    "    sample_1 = sample_xy[:,:,:,:,0]\n",
    "    sample_2 = sample_xy[:,:,:,:,1]\n",
    "    sample_3 = sample_xy[:,:,:,:,2]\n",
    "    sample_4 = sample_xy[:,:,:,:,3]\n",
    "    sample_5 = sample_xy[:,:,:,:,4]\n",
    "    \n",
    "    label_c_valance = label_c_xy[:,:,:,:,0]\n",
    "    label_c_arousal = label_c_xy[:,:,:,:,1]\n",
    "    \n",
    "    # using indicator for training\n",
    "    # video_label_3D = np.repeat(video_label[:,np.newaxis,:],series_len,1)\n",
    "    # video_label_4D = np.repeat(video_label_3D[:,:,np.newaxis,:],y_dim,2)\n",
    "    # video_label_xy = np.repeat(video_label_4D[:,:,:,np.newaxis,:],x_dim,3)\n",
    "    # video_label_xy.astype(float)\n",
    "    print ('=========================   normalize data   ===========================')\n",
    "    sample_1_norm = dlacs.preprocess.operator.normalize(sample_1)\n",
    "    sample_2_norm = dlacs.preprocess.operator.normalize(sample_2)\n",
    "    sample_3_norm = dlacs.preprocess.operator.normalize(sample_3)\n",
    "    sample_4_norm = dlacs.preprocess.operator.normalize(sample_4)\n",
    "    sample_5_norm = dlacs.preprocess.operator.normalize(sample_5)\n",
    "    \n",
    "    label_c_valance_norm = dlacs.preprocess.operator.normalize(label_c_valance)\n",
    "    label_c_arousal_norm = dlacs.preprocess.operator.normalize(label_c_arousal)\n",
    "    print('================  save the normalizing factor  =================')\n",
    "    sample_1_max = np.amax(sample_1)\n",
    "    sample_1_min = np.amin(sample_1)\n",
    "    sample_2_max = np.amax(sample_2)\n",
    "    sample_2_min = np.amin(sample_2)\n",
    "    sample_3_max = np.amax(sample_3)\n",
    "    sample_3_min = np.amin(sample_3)\n",
    "    sample_4_max = np.amax(sample_4)\n",
    "    sample_4_min = np.amin(sample_4)\n",
    "    sample_5_max = np.amax(sample_5)\n",
    "    sample_5_min = np.amin(sample_5)\n",
    "    \n",
    "    label_c_valance_max = np.amax(label_c_valance)\n",
    "    label_c_valance_min = np.amin(label_c_valance)\n",
    "    label_c_arousal_max = np.amax(label_c_arousal)\n",
    "    label_c_arousal_min = np.amin(label_c_arousal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3690, 1000, 8)\n",
      "(3690, 1000, 2)\n",
      "(3690, 2)\n",
      "(3690, 1)\n",
      "(3690, 1)\n",
      "(3690, 40, 5, 5, 2)\n",
      "=======================\n"
     ]
    }
   ],
   "source": [
    "    # first check of data shape\n",
    "    print(sample.shape)\n",
    "    print(label_c.shape)\n",
    "    print(label.shape)\n",
    "    print(subject.shape)\n",
    "    print(video_label.shape)\n",
    "    # check of reshape\n",
    "    print(label_c_xy.shape)\n",
    "    #print(sample[300,:100,1])\n",
    "    print(\"=======================\")\n",
    "    #print(sample_xy[300,:4,:,:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procedure for LSTM <br>\n",
    "** We use Pytorth to implement LSTM neural network with time series of climate data. ** <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************  create basic dimensions for tensor and network  *********************\n",
      "1.1.0\n",
      "Is CUDA available? True\n",
      "*******************  cross validation and testing data  *********************\n"
     ]
    }
   ],
   "source": [
    "    print ('*******************  create basic dimensions for tensor and network  *********************')\n",
    "    # specifications of neural network\n",
    "    input_channels = 5\n",
    "    #hidden_channels = [3, 3, 2] # number of channels & hidden layers, the channels of last layer is the channels of output, too\n",
    "    #hidden_channels = [3, 3, 3, 3, 2]\n",
    "    hidden_channels = [2]\n",
    "    kernel_size = 3\n",
    "    # here we input a sequence and predict the next step only\n",
    "    learning_rate = 0.01\n",
    "    num_epochs = 100\n",
    "    print (torch.__version__)\n",
    "    # check if CUDA is available\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    print(\"Is CUDA available? {}\".format(use_cuda))\n",
    "    # CUDA settings torch.__version__ must > 0.4\n",
    "    # !!! This is important for the model!!! The first option is gpu\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print ('*******************  cross validation and testing data  *********************')\n",
    "    # take 10% years as testing data\n",
    "    test_len = batch_size // 10 * 2\n",
    "    # iterations\n",
    "    iterations = batch_size - test_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************  load exsited LSTM model  *********************\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\nosta\\\\ConvLSTM_emotion\\\\results\\\\convlstm_emotion_hl_1_kernel_3_lr_0.01_epoch_500_validSIC.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    380\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0municode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\nosta\\\\ConvLSTM_emotion\\\\results\\\\convlstm_emotion_hl_1_kernel_3_lr_0.01_epoch_500_validSIC.pkl'"
     ]
    }
   ],
   "source": [
    "    %%time\n",
    "    print ('*******************  load exsited LSTM model  *********************')\n",
    "    # load model parameters\n",
    "    model = dlacs.ConvLSTM.ConvLSTM(input_channels, hidden_channels, kernel_size).to(device)\n",
    "    model.load_state_dict(torch.load(os.path.join(output_path, 'convlstm_emotion_hl_1_kernel_3_lr_0.01_epoch_500_validSIC.pkl'),\n",
    "                                     map_location=device))\n",
    "    #model = torch.load(os.path.join(output_path, 'Barents','convlstm_emotion_hl_1_kernel_3_lr_0.01_epoch_500_validSIC.pkl'))\n",
    "    print(model)\n",
    "    # check the sequence length (dimension in need for post-processing)\n",
    "    _, sequence_len, height, width = sample_1_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************  run LSTM  *********************\n",
      "The model is designed to make many to one prediction.\n",
      "A series of multi-chanel variables will be input to the model.\n",
      "The model learns by verifying the output at each timestep.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Anaconda\\lib\\site-packages\\torch\\nn\\_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvLSTM(\n",
      "  (cell0): ConvLSTMCell(\n",
      "    (Wxi): Conv2d(5, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (Whi): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (Wxf): Conv2d(5, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (Whf): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (Wxc): Conv2d(5, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (Whc): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (Wxo): Conv2d(5, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (Who): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "MSELoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.01\n",
      "    weight_decay: 0\n",
      ")\n",
      "Wall time: 7 s\n"
     ]
    }
   ],
   "source": [
    "    %%time\n",
    "    print ('*******************  run LSTM  *********************')\n",
    "    print ('The model is designed to make many to one prediction.')\n",
    "    print ('A series of multi-chanel variables will be input to the model.')\n",
    "    print ('The model learns by verifying the output at each timestep.')\n",
    "    # check the sequence length\n",
    "    _, sequence_len, height, width = sample_1_norm.shape\n",
    "    # initialize our model\n",
    "    model = dlacs.ConvLSTM.ConvLSTM(input_channels, hidden_channels, kernel_size).to(device)\n",
    "    loss_fn = torch.nn.MSELoss(size_average=True)\n",
    "    # stochastic gradient descent\n",
    "    #optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    # Adam optimizer\n",
    "    optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    print(model)\n",
    "    print(loss_fn)\n",
    "    print(optimiser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell0.Wxi.weight\n",
      "tensor([[[[-0.0462,  0.0080, -0.0835],\n",
      "          [ 0.1415,  0.1050, -0.0149],\n",
      "          [-0.0819, -0.1153, -0.1139]],\n",
      "\n",
      "         [[-0.1280,  0.0669,  0.0994],\n",
      "          [ 0.0641, -0.0091, -0.1008],\n",
      "          [ 0.0709,  0.0190, -0.1305]],\n",
      "\n",
      "         [[ 0.1098,  0.0286, -0.0751],\n",
      "          [ 0.1438,  0.0837,  0.1393],\n",
      "          [-0.0610, -0.0658,  0.1107]],\n",
      "\n",
      "         [[ 0.1442,  0.1400, -0.1337],\n",
      "          [ 0.0109, -0.0077,  0.0062],\n",
      "          [-0.1268,  0.0479, -0.0059]],\n",
      "\n",
      "         [[-0.0267,  0.0680, -0.1253],\n",
      "          [ 0.0656,  0.1415,  0.1333],\n",
      "          [-0.1431, -0.0730,  0.0952]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0676,  0.0405, -0.1113],\n",
      "          [-0.1024,  0.0473, -0.0706],\n",
      "          [ 0.0761, -0.1360, -0.0666]],\n",
      "\n",
      "         [[-0.0577, -0.1429, -0.0058],\n",
      "          [ 0.0075, -0.1271, -0.1442],\n",
      "          [-0.0007, -0.0369, -0.1170]],\n",
      "\n",
      "         [[ 0.0250, -0.1097,  0.1011],\n",
      "          [ 0.0515, -0.0578, -0.0964],\n",
      "          [ 0.0106, -0.0379, -0.0005]],\n",
      "\n",
      "         [[-0.1165,  0.0069, -0.0311],\n",
      "          [ 0.0714,  0.0320, -0.0287],\n",
      "          [ 0.0258, -0.0779, -0.0689]],\n",
      "\n",
      "         [[ 0.0335, -0.0163, -0.0335],\n",
      "          [-0.0620, -0.1270,  0.0463],\n",
      "          [ 0.1068, -0.1040,  0.0804]]]], device='cuda:0')\n",
      "torch.Size([2, 5, 3, 3])\n",
      "=========================\n",
      "cell0.Wxi.bias\n",
      "tensor([ 0.0082, -0.1239], device='cuda:0')\n",
      "torch.Size([2])\n",
      "=========================\n",
      "cell0.Whi.weight\n",
      "tensor([[[[ 0.2224,  0.1471,  0.0304],\n",
      "          [ 0.0607,  0.0100, -0.2149],\n",
      "          [-0.0449,  0.1890, -0.1897]],\n",
      "\n",
      "         [[ 0.1189, -0.1652, -0.2044],\n",
      "          [ 0.0362, -0.2103,  0.0074],\n",
      "          [-0.1596, -0.0616, -0.0757]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1746, -0.2193, -0.2345],\n",
      "          [ 0.1731, -0.1000, -0.1208],\n",
      "          [ 0.0935,  0.1443,  0.0904]],\n",
      "\n",
      "         [[ 0.0321,  0.2075,  0.1338],\n",
      "          [-0.1763, -0.1791,  0.0465],\n",
      "          [ 0.0636,  0.0350, -0.1402]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 3, 3])\n",
      "=========================\n",
      "cell0.Wxf.weight\n",
      "tensor([[[[ 0.0846, -0.0249,  0.1231],\n",
      "          [ 0.0277,  0.1230, -0.1356],\n",
      "          [ 0.0794,  0.1106,  0.0791]],\n",
      "\n",
      "         [[-0.0382, -0.0726, -0.0146],\n",
      "          [ 0.0425,  0.0961,  0.0817],\n",
      "          [ 0.0215, -0.0311,  0.1280]],\n",
      "\n",
      "         [[ 0.0467,  0.0017,  0.0971],\n",
      "          [-0.0766,  0.0427, -0.0276],\n",
      "          [-0.0191,  0.1107,  0.0313]],\n",
      "\n",
      "         [[-0.1322,  0.0281,  0.1349],\n",
      "          [ 0.0764,  0.0447,  0.0841],\n",
      "          [-0.0465, -0.0052,  0.0620]],\n",
      "\n",
      "         [[-0.0353, -0.1239,  0.1257],\n",
      "          [ 0.1212, -0.0448, -0.0784],\n",
      "          [ 0.0123,  0.1102,  0.1447]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0189,  0.0620,  0.0537],\n",
      "          [ 0.0617, -0.1400, -0.0074],\n",
      "          [-0.1221,  0.1279, -0.1453]],\n",
      "\n",
      "         [[ 0.0398, -0.0964,  0.1285],\n",
      "          [ 0.0178, -0.0264, -0.1364],\n",
      "          [-0.1378,  0.0805, -0.0332]],\n",
      "\n",
      "         [[-0.0947,  0.0275,  0.0552],\n",
      "          [-0.0204, -0.0919, -0.0397],\n",
      "          [-0.1211,  0.1146, -0.0017]],\n",
      "\n",
      "         [[-0.0099, -0.1444,  0.1223],\n",
      "          [ 0.0151, -0.1067,  0.1366],\n",
      "          [-0.1220, -0.1405,  0.0344]],\n",
      "\n",
      "         [[ 0.1216, -0.1008,  0.0369],\n",
      "          [ 0.0342,  0.0308, -0.0613],\n",
      "          [-0.0354,  0.1004,  0.0143]]]], device='cuda:0')\n",
      "torch.Size([2, 5, 3, 3])\n",
      "=========================\n",
      "cell0.Wxf.bias\n",
      "tensor([0.0604, 0.0464], device='cuda:0')\n",
      "torch.Size([2])\n",
      "=========================\n",
      "cell0.Whf.weight\n",
      "tensor([[[[-0.0601, -0.2224,  0.0307],\n",
      "          [-0.1135, -0.0086,  0.2317],\n",
      "          [-0.2251,  0.1502, -0.1222]],\n",
      "\n",
      "         [[-0.0416, -0.1507,  0.1001],\n",
      "          [-0.0661, -0.0733, -0.1883],\n",
      "          [ 0.1059,  0.1007, -0.1971]]],\n",
      "\n",
      "\n",
      "        [[[-0.0342, -0.0231, -0.0395],\n",
      "          [-0.2218, -0.1310, -0.0613],\n",
      "          [ 0.1150,  0.1609, -0.2300]],\n",
      "\n",
      "         [[ 0.0488, -0.0485,  0.1643],\n",
      "          [-0.2117, -0.1217, -0.1539],\n",
      "          [ 0.1114,  0.0064, -0.0573]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 3, 3])\n",
      "=========================\n",
      "cell0.Wxc.weight\n",
      "tensor([[[[ 0.1292, -0.0217,  0.0176],\n",
      "          [ 0.0170, -0.0857,  0.1131],\n",
      "          [-0.0478, -0.0048,  0.0327]],\n",
      "\n",
      "         [[ 0.0330,  0.0473, -0.1361],\n",
      "          [-0.0706,  0.0540, -0.1171],\n",
      "          [ 0.1402, -0.1387, -0.0684]],\n",
      "\n",
      "         [[ 0.1434, -0.0495, -0.0745],\n",
      "          [-0.0975, -0.0504, -0.1333],\n",
      "          [-0.1237, -0.0203,  0.0489]],\n",
      "\n",
      "         [[-0.1398, -0.1467, -0.0359],\n",
      "          [ 0.0635,  0.0701,  0.1306],\n",
      "          [ 0.0870, -0.1229,  0.0004]],\n",
      "\n",
      "         [[ 0.0287,  0.0910,  0.1108],\n",
      "          [-0.1367, -0.0110,  0.1406],\n",
      "          [-0.1184, -0.0726,  0.0806]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1378, -0.0895, -0.0164],\n",
      "          [ 0.1307, -0.0862, -0.0147],\n",
      "          [-0.0948,  0.0875,  0.0478]],\n",
      "\n",
      "         [[ 0.0188,  0.0013, -0.0509],\n",
      "          [ 0.0965,  0.1028,  0.1364],\n",
      "          [ 0.0340, -0.1144, -0.1375]],\n",
      "\n",
      "         [[ 0.1468, -0.1245,  0.0749],\n",
      "          [ 0.1027,  0.1067, -0.1119],\n",
      "          [ 0.1276,  0.0189,  0.1259]],\n",
      "\n",
      "         [[-0.0707, -0.0634,  0.0373],\n",
      "          [ 0.0888,  0.0652,  0.0766],\n",
      "          [ 0.0656,  0.0357,  0.0840]],\n",
      "\n",
      "         [[-0.0590,  0.0525,  0.1357],\n",
      "          [ 0.0312, -0.0457, -0.0139],\n",
      "          [-0.1429,  0.0383,  0.1230]]]], device='cuda:0')\n",
      "torch.Size([2, 5, 3, 3])\n",
      "=========================\n",
      "cell0.Wxc.bias\n",
      "tensor([0.0967, 0.0781], device='cuda:0')\n",
      "torch.Size([2])\n",
      "=========================\n",
      "cell0.Whc.weight\n",
      "tensor([[[[ 0.1495,  0.1515, -0.1610],\n",
      "          [-0.1455, -0.0252,  0.1255],\n",
      "          [-0.0410, -0.1620, -0.1051]],\n",
      "\n",
      "         [[-0.1956, -0.0981,  0.1482],\n",
      "          [ 0.0134,  0.2175,  0.0450],\n",
      "          [ 0.1258,  0.0933, -0.1179]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1660, -0.0034,  0.0398],\n",
      "          [ 0.2135, -0.2146,  0.0008],\n",
      "          [ 0.1689,  0.2210,  0.1980]],\n",
      "\n",
      "         [[ 0.0264,  0.0478, -0.1663],\n",
      "          [-0.1807, -0.1513,  0.1744],\n",
      "          [ 0.1550, -0.0313, -0.1623]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 3, 3])\n",
      "=========================\n",
      "cell0.Wxo.weight\n",
      "tensor([[[[-0.1236, -0.1040, -0.1368],\n",
      "          [-0.1006,  0.0352, -0.0746],\n",
      "          [-0.0211, -0.1006,  0.0798]],\n",
      "\n",
      "         [[ 0.0863, -0.0068,  0.0152],\n",
      "          [ 0.0512, -0.1200, -0.1088],\n",
      "          [-0.0394, -0.0340,  0.1409]],\n",
      "\n",
      "         [[ 0.1152,  0.1070,  0.0159],\n",
      "          [-0.0422,  0.0856,  0.0131],\n",
      "          [ 0.0440,  0.0865, -0.0477]],\n",
      "\n",
      "         [[-0.0195, -0.0859, -0.1122],\n",
      "          [ 0.0520, -0.0151,  0.0851],\n",
      "          [ 0.0461,  0.1119,  0.0687]],\n",
      "\n",
      "         [[ 0.1160,  0.0200,  0.1299],\n",
      "          [ 0.0797,  0.0916,  0.0573],\n",
      "          [-0.0064,  0.0644,  0.0101]]],\n",
      "\n",
      "\n",
      "        [[[-0.0856,  0.1446, -0.1237],\n",
      "          [-0.1321, -0.0099, -0.0715],\n",
      "          [ 0.0247,  0.0314, -0.1413]],\n",
      "\n",
      "         [[-0.1151, -0.0905, -0.1125],\n",
      "          [-0.0275,  0.0119,  0.0818],\n",
      "          [ 0.0837,  0.0225,  0.0822]],\n",
      "\n",
      "         [[ 0.0192, -0.0298,  0.1030],\n",
      "          [ 0.0796, -0.0172, -0.1171],\n",
      "          [ 0.0346, -0.0463,  0.0649]],\n",
      "\n",
      "         [[-0.0478, -0.1436,  0.1092],\n",
      "          [-0.0079,  0.1125,  0.1472],\n",
      "          [ 0.0189, -0.1366, -0.0857]],\n",
      "\n",
      "         [[ 0.1188, -0.0563,  0.0460],\n",
      "          [ 0.0185,  0.0902,  0.0849],\n",
      "          [ 0.0789,  0.0668, -0.1056]]]], device='cuda:0')\n",
      "torch.Size([2, 5, 3, 3])\n",
      "=========================\n",
      "cell0.Wxo.bias\n",
      "tensor([-0.0465,  0.0640], device='cuda:0')\n",
      "torch.Size([2])\n",
      "=========================\n",
      "cell0.Who.weight\n",
      "tensor([[[[ 0.0942,  0.1899, -0.0379],\n",
      "          [-0.1165, -0.0863, -0.0424],\n",
      "          [ 0.2276, -0.0903, -0.0356]],\n",
      "\n",
      "         [[ 0.0406, -0.1165, -0.0082],\n",
      "          [-0.2335,  0.1486, -0.2275],\n",
      "          [ 0.1587, -0.0119, -0.0848]]],\n",
      "\n",
      "\n",
      "        [[[-0.0354, -0.0480,  0.0453],\n",
      "          [-0.0244,  0.0434,  0.0499],\n",
      "          [-0.1977, -0.1257,  0.1449]],\n",
      "\n",
      "         [[-0.2031,  0.1514, -0.0061],\n",
      "          [-0.2024, -0.0998, -0.0148],\n",
      "          [-0.0308,  0.0064, -0.1589]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 3, 3])\n",
      "=========================\n"
     ]
    }
   ],
   "source": [
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print (name)\n",
    "            print (param.data)\n",
    "            print (param.size())\n",
    "            print (\"=========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################################\n",
      "#############  preview model parameters matrix  ###############\n",
      "##############################################################\n",
      "Number of parameter matrices:  12\n",
      "torch.Size([2, 5, 3, 3])\n",
      "torch.Size([2])\n",
      "torch.Size([2, 2, 3, 3])\n",
      "torch.Size([2, 5, 3, 3])\n",
      "torch.Size([2])\n",
      "torch.Size([2, 2, 3, 3])\n",
      "torch.Size([2, 5, 3, 3])\n",
      "torch.Size([2])\n",
      "torch.Size([2, 2, 3, 3])\n",
      "torch.Size([2, 5, 3, 3])\n",
      "torch.Size([2])\n",
      "torch.Size([2, 2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "    print('##############################################################')\n",
    "    print('#############  preview model parameters matrix  ###############')\n",
    "    print('##############################################################')\n",
    "    print('Number of parameter matrices: ', len(list(model.parameters())))\n",
    "    for i in range(len(list(model.parameters()))):\n",
    "        print(list(model.parameters())[i].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################################\n",
      "##################  start training loop  #####################\n",
      "##############################################################\n",
      "Epoch 0 Iteration 0 MSE: 17.856\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \"\"\"\n\u001b[1;32m--> 107\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "    %%time\n",
    "    print('##############################################################')\n",
    "    print('##################  start training loop  #####################')\n",
    "    print('##############################################################')\n",
    "    hist = np.zeros(num_epochs * iterations)\n",
    "    # loop of epoch\n",
    "    for t in range(num_epochs):\n",
    "        for i in range(iterations):\n",
    "            # Clear stored gradient\n",
    "            model.zero_grad()\n",
    "            # loop of timestep\n",
    "            for timestep in range(sequence_len):\n",
    "                # hidden state re-initialized inside the model when timestep=0\n",
    "                #################################################################################\n",
    "                ########          create input tensor with multi-input dimension         ########\n",
    "                #################################################################################\n",
    "                # create variables\n",
    "                x_input = np.stack((sample_1_norm[i,timestep,:,:],\n",
    "                                    sample_2_norm[i,timestep,:,:],\n",
    "                                    sample_3_norm[i,timestep,:,:],\n",
    "                                    sample_4_norm[i,timestep,:,:],\n",
    "                                    sample_5_norm[i,timestep,:,:])) #vstack,hstack,dstack\n",
    "                x_var = torch.autograd.Variable(torch.Tensor(x_input).view(-1,input_channels,height,width)).to(device)\n",
    "                #################################################################################\n",
    "                ########       create training tensor with multi-input dimension         ########\n",
    "                #################################################################################\n",
    "                y_train_stack = np.stack((label_c_valance_norm[i,timestep,:,:],\n",
    "                                          label_c_arousal_norm[i,timestep,:,:])) #vstack,hstack,dstack\n",
    "                y_var = torch.autograd.Variable(torch.Tensor(y_train_stack).view(-1,hidden_channels[-1],height,width)).to(device)\n",
    "                #################################################################################   \n",
    "                # Forward pass\n",
    "                y_pred, _ = model(x_var, timestep)\n",
    "                # choose training data\n",
    "                y_train = y_var        \n",
    "                # torch.nn.functional.mse_loss(y_pred, y_train) can work with (scalar,vector) & (vector,vector)\n",
    "                # Please Make Sure y_pred & y_train have the same dimension\n",
    "                # accumulate loss\n",
    "                if timestep == 0:\n",
    "                    loss = loss_fn(y_pred, y_train)\n",
    "                else:\n",
    "                    loss += loss_fn(y_pred, y_train)\n",
    "                #print (timestep)\n",
    "            #print(y_pred.shape)\n",
    "            #print(y_train.shape)\n",
    "            # print loss at certain iteration\n",
    "            if i % 1000 == 0:\n",
    "                print(\"Epoch {} Iteration {} MSE: {:0.3f}\".format(t, i, loss.item()))\n",
    "                # Gradcheck requires double precision numbers to run\n",
    "                #res = torch.autograd.gradcheck(loss_fn, (y_pred.double(), y_train.double()), eps=1e-6, raise_exception=True)\n",
    "                #print(res)\n",
    "            hist[i+t*iterations] = loss.item()\n",
    "\n",
    "            # Zero out gradient, else they will accumulate between epochs\n",
    "            optimiser.zero_grad()\n",
    "    \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Update parameters\n",
    "            optimiser.step()\n",
    "        \n",
    "    # save the model\n",
    "    # (recommended) save the model parameters only\n",
    "    torch.save(model.state_dict(), os.path.join(output_path,'convlstm_emotion.pkl'))\n",
    "    # save the entire model\n",
    "    #torch.save(model, os.path.join(output_path,'convlstm.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************  Loss with time  **********************\n",
      "*******************  Loss with time (log)  **********************\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    #################################################################################\n",
    "    ###########                 after training statistics                 ###########\n",
    "    #################################################################################\n",
    "    print (\"*******************  Loss with time  **********************\")\n",
    "    fig00 = plt.figure()\n",
    "    plt.plot(hist, 'r', label=\"Training loss\")\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Error')\n",
    "    plt.legend()\n",
    "    fig00.savefig(os.path.join(output_path,'ConvLSTM_train_error.png'),dpi=150)\n",
    "    \n",
    "    print (\"*******************  Loss with time (log)  **********************\")\n",
    "    fig01 = plt.figure()\n",
    "    plt.plot(np.log(hist), 'r', label=\"Training loss\")\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Log error')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    fig01.savefig(os.path.join(output_path,'ConvLSTM_train_log_error.png'),dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    print ('*******************  evaluation matrix  *********************')\n",
    "    # The prediction will be evaluated through RMSE against climatology\n",
    "    \n",
    "    # error score for temporal-spatial fields, without keeping spatial pattern\n",
    "    def RMSE(x,y):\n",
    "        \"\"\"\n",
    "        Calculate the RMSE. x is input series and y is reference series.\n",
    "        It calculates RMSE over the domain, not over time. The spatial structure\n",
    "        will not be kept.\n",
    "        Parameter\n",
    "        ----------------------\n",
    "        x: input time series with the shape [time, lat, lon]\n",
    "        \"\"\"\n",
    "        x_series = x.reshape(x.shape[0],-1)\n",
    "        y_series = y.reshape(y.shape[0],-1)\n",
    "        rmse = np.sqrt(np.mean((x_series - y_series)**2,1))\n",
    "        rmse_std = np.sqrt(np.std((x_series - y_series)**2,1))\n",
    "    \n",
    "        return rmse, rmse_std\n",
    "    \n",
    "    # error score for temporal-spatial fields, keeping spatial pattern\n",
    "    def MAE(x,y):\n",
    "        \"\"\"\n",
    "        Calculate the MAE. x is input series and y is reference series.\n",
    "        It calculate MAE over time and keeps the spatial structure.\n",
    "        \"\"\"\n",
    "        mae = np.mean(np.abs(x-y),0)\n",
    "        \n",
    "        return mae\n",
    "    \n",
    "    def MSE(x, y):\n",
    "        \"\"\"\n",
    "        Calculate the MSE. x is input series and y is reference series.\n",
    "        \"\"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    %%time\n",
    "    #################################################################################\n",
    "    ########                           prediction                            ########\n",
    "    #################################################################################\n",
    "    print('##############################################################')\n",
    "    print('###################  start prediction loop ###################')\n",
    "    print('##############################################################')\n",
    "    # forecast array\n",
    "    pred_valance = np.zeros((test_len, series_len, y_dim, x_dim),dtype=float)\n",
    "    pred_arousal = np.zeros((test_len, series_len, y_dim, x_dim),dtype=float)\n",
    "    for n in range(test_len):\n",
    "        # Clear stored gradient\n",
    "        model.zero_grad()\n",
    "        for timestep in range(sequence_len):\n",
    "            x_input = np.stack((sample_1_norm[batch_size-test_len+n,sequence_len,:,:],\n",
    "                                sample_2_norm[batch_size-test_len+n,sequence_len,:,:],\n",
    "                                sample_3_norm[batch_size-test_len+n,sequence_len,:,:],\n",
    "                                sample_4_norm[batch_size-test_len+n,sequence_len,:,:],\n",
    "                                sample_5_norm[batch_size-test_len+n,sequence_len,:,:]))\n",
    "            x_var_pred = torch.autograd.Variable(torch.Tensor(x_input).view(-1,input_channels,height,width),\n",
    "                                                 requires_grad=False).to(device)\n",
    "            # make prediction\n",
    "            last_pred, _ = model(x_var_pred, timestep)\n",
    "            # GPU data should be transferred to CPU\n",
    "            pred_valance[n,timestep,:,:] = last_pred[0,0,:,:].cpu().data.numpy()\n",
    "            pred_arousal[n,timestep,:,:] = last_pred[0,1,:,:].cpu().data.numpy()\n",
    "    \n",
    "    # save prediction as npz file\n",
    "    np.savez_compressed(os.path.koin(output_path,'ConvLSTM_emotion_pred.npz'),\n",
    "                        valance=pred_valance, arousal=pred_arousal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #####################################################################################\n",
    "    ########         visualization of prediction and implement metrics           ########\n",
    "    #####################################################################################\n",
    "    # plot\n",
    "    # compute mse\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
